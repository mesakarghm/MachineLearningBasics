{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [[\"Green\",3,\"Mango\"],[\"Yellow\",3,\"Mango\"],['Red',1,'Grape'],['Red',1,'Grape'],['Yellow',3,'Lemon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column labels \n",
    "header = ['Color','Diameter','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_vals(rows, col): \n",
    "    return set([row[col] for row in rows])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_counts(rows): \n",
    "    \"\"\"Counts the number of each type of example in a dataset\"\"\"\n",
    "    counts = {} \n",
    "    for row in rows: \n",
    "        #in our dataset format, the label is the last column \n",
    "        label = row[-1]\n",
    "        if label not in counts: \n",
    "            counts[label] = 0\n",
    "        counts[label] +=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_numeric(value): \n",
    "    \"\"\"test if a value is numeric or not \"\"\"\n",
    "    return isinstance(value, int) or isinstance(value,float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Question: \n",
    "    \"\"\"A question is used to partition a dataset\n",
    "    This class just records a column number e.g. 0 for color and 'column value' e.g. Green. \n",
    "    The 'match' method is used to compare the feature value in an example to the feature \n",
    "    value stored in the question.\"\"\"\n",
    "    def __init__(self, column, value): \n",
    "        self.column = column \n",
    "        self.value = value \n",
    "    def match(self, example): \n",
    "        #compare the feature value in an example to the feature value in this question \n",
    "        val = example[self.column]\n",
    "        if is_numeric(val): \n",
    "            return val>=self.value\n",
    "        else: \n",
    "            return val == self.value\n",
    "    def __repr__(self): \n",
    "        #helper function to print the question to a readable format\n",
    "        condition = \"==\"\n",
    "        if is_numeric(self.value): \n",
    "            condition = \">=\"\n",
    "        return \"Is %s %s %s\" %(header[self.column],condition, str(self.value))\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(rows, question): \n",
    "    \"\"\"used to partition a dataset \n",
    "    \n",
    "    For each row in the dataset, check if it matches the question. If so,\n",
    "    add it to 'true rows'; otherwise, add it to 'false rows'.....\"\"\"\n",
    "    \n",
    "    true_rows, false_rows = [],[]\n",
    "    for row in rows: \n",
    "        if question.match(row): \n",
    "            true_rows.append(row)\n",
    "        else: \n",
    "            false_rows.append(row)\n",
    "    return true_rows, false_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(rows): \n",
    "    \"\"\"calculate the Gini impurity for a list of rows\"\"\"\n",
    "    counts = class_counts(rows)\n",
    "    impurity = 1\n",
    "    for lbl in counts: \n",
    "        prob_of_lbl = counts[lbl] / float(len(rows))\n",
    "        impurity -= prob_of_lbl ** 2\n",
    "    return impurity \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(left, right, current_uncertainity): \n",
    "    \"\"\"Information Gain. \n",
    "    The uncertainity of the starting node, minus the weighted impurity of the two child nodes\"\"\"\n",
    "    p = float(len(left)) / (len(left)+ len(right))\n",
    "    return current_uncertainity - p * gini(left) -  (1-p) * gini(right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(rows): \n",
    "    \"\"\"Find the best question to ask by iterating over every feature / value and calculating information gain \"\"\"\n",
    "    best_gain = 0 \n",
    "    best_question = None \n",
    "    current_uncertainity = gini(rows)\n",
    "    n_features = len(rows[0])\n",
    "    \n",
    "    for col in range(n_features): \n",
    "        values = set([row[col] for row in rows])\n",
    "        for val in values: \n",
    "            question = Question(col, val)\n",
    "            #try splitting the dataset \n",
    "            true_rows, false_rows = partition(rows, question)\n",
    "            #skip this split if it doesn't divide the dataset \n",
    "            if len(true_rows) == 0 or len(false_rows) == 0: \n",
    "                continue \n",
    "                \n",
    "            #calculate the information gain from this split \n",
    "            gain = info_gain(true_rows, false_rows, current_uncertainity)\n",
    "            \n",
    "            if gain >= best_gain: \n",
    "                best_gain, best_question = gain, question \n",
    "    return best_gain, best_question\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Leaf: \n",
    "    \"\"\"A leaf node classifies the data\n",
    "    This holds a dictionary of class (e.g. \"Mango\") --> number of times it appears in rows \n",
    "    from training data that reach this leaf\"\"\"\n",
    "    def __init__(self,rows): \n",
    "        self.predictions = class_counts(rows)\n",
    "class Decision_Node(): \n",
    "    \"\"\"A decision Node asks a question. This holds a reference to the quesiton, and to the child nodes\"\"\"\n",
    "    def __init__(self, question,true_branch,false_branch):\n",
    "        self.question = question \n",
    "        self.true_branch = true_branch \n",
    "        self.false_branch = false_branch \n",
    "\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(rows): \n",
    "    \"\"\"Bulids the tree \"\"\"\n",
    "    #Try partitioning the dataset on each of the unique attribute \n",
    "    #calculate the information gain \n",
    "    #and return the question that produces the highest gain \n",
    "    \n",
    "    gain, question = find_best_split(rows)\n",
    "    \n",
    "    #base case: no further info gain \n",
    "    #since we can ask no further question, \n",
    "    #we'll return a leaft \n",
    "    if gain == 0 : \n",
    "        return Leaf(rows)\n",
    "    # if we reach here, we have found a useful feature/ value to partition on \n",
    "    true_rows, false_rows = partition(rows, question)\n",
    "    \n",
    "    #recursively build the true branch \n",
    "    true_branch = build_tree(true_rows)\n",
    "    \n",
    "    #recursively build the false branch \n",
    "    false_branch = build_tree(false_rows)\n",
    "    \n",
    "    #return a question node \n",
    "    #this records the best feature / value to ask at this point, \n",
    "    #as well as the branches to follow \n",
    "    #depending on the answer \n",
    "    return Decision_Node(question, true_branch, false_branch)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node , spacing = \" \"): \n",
    "    \n",
    "    #Base case: we've reached a leaf \n",
    "    if isinstance(node, Leaf): \n",
    "        print(spacing + \"Predict\", node.predictions)\n",
    "        return \n",
    "    #print the question at this node \n",
    "    print(spacing + str(node.question))\n",
    "    \n",
    "    #call this function recursively on the true branch \n",
    "    print(spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "    \n",
    "    #call this function recursively on the false branch \n",
    "    print(spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(row, node): \n",
    "    #base case: we have reached a leaf \n",
    "    if isinstance(node, Leaf): \n",
    "        return node.predictions \n",
    "    \n",
    "    #decide whether to follow the true branch or the false branch \n",
    "    #compare the feature/ value stored in the node to the example we're considering \n",
    "    if node.question.match(row): \n",
    "        return classify(row, node.true_branch)\n",
    "    else: \n",
    "        return classify(row, node.false_branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_leaf(counts): \n",
    "    \"\"\"prints the predictions at a leaf\"\"\"\n",
    "    total = sum(counts.values()) * 1.0\n",
    "    probs = {}\n",
    "    for lbl in counts.keys(): \n",
    "        probs[lbl] = str(int(counts[lbl]/total * 100)) + '%'\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is Label == Grape\n",
      " --> True:\n",
      "   Predict {'Grape': 2}\n",
      " --> False:\n",
      "   Is Label == Mango\n",
      "   --> True:\n",
      "     Predict {'Mango': 2}\n",
      "   --> False:\n",
      "     Predict {'Lemon': 1}\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = [['Green',3,'Mango'],['Yellow',4,'Mango'],['Red',2,'Grape'],['Red',1,'Grape'],['Yellow',3,'Lemon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : Mango, Predicted : {'Mango': '100%'}\n",
      "Actual : Mango, Predicted : {'Mango': '100%'}\n",
      "Actual : Grape, Predicted : {'Grape': '100%'}\n",
      "Actual : Grape, Predicted : {'Grape': '100%'}\n",
      "Actual : Lemon, Predicted : {'Lemon': '100%'}\n"
     ]
    }
   ],
   "source": [
    "for row in testing_data: \n",
    "    print(\"Actual : %s, Predicted : %s\"%(row[-1],print_leaf(classify(row,my_tree))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
